{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51388c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, './code')\n",
    "from sqlnet.utils import *\n",
    "from sqlnet.model.sqlnet import SQLNet\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b4ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_word=768\n",
    "bert_path = 'code/chinese_L-12_H-768_A-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7472082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "Loaded 4396 data from data/val/val.json\n",
      "Loaded 1197 data from data/val/val.tables.json\n",
      "Loaded 4086 data from data/test/test.json\n",
      "Loaded 1102 data from data/test/test.tables.json\n"
     ]
    }
   ],
   "source": [
    "dev_sql, dev_table, dev_db, test_sql, test_table, test_db = load_dataset(use_small=False, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d562a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  21128\n",
      "hidden_size:  768\n",
      "num_hidden_layer:  12\n",
      "num_attention_heads:  12\n",
      "hidden_act:  gelu\n",
      "intermediate_size:  3072\n",
      "hidden_dropout_prob:  0.1\n",
      "attention_probs_dropout_prob:  0.1\n",
      "max_position_embeddings:  512\n",
      "type_vocab_size:  2\n",
      "initializer_range:  0.02\n",
      "Load pre-trained parameters.\n",
      "Using column attention on select number predicting\n",
      "Using column attention on selection predicting\n",
      "Using column attention on aggregator predicting\n",
      "Using column attention on where predicting\n",
      "Using column attention on where relation predicting\n",
      "Loading from saved_model/best_model\n",
      "Loaded model from saved_model/best_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SQLNet(\n",
       "  (sel_num): SelNumPredictor(\n",
       "    (sel_num_lstm): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (sel_num_att): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (sel_num_col_att): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (sel_num_out): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=768, out_features=4, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (sel_num_col2hid1): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (sel_num_col2hid2): Linear(in_features=768, out_features=1536, bias=True)\n",
       "  )\n",
       "  (sel_pred): SelPredictor(\n",
       "    (sel_lstm): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (sel_att): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (sel_col_name_enc): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (sel_out_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (sel_out_col): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (sel_out): Sequential(\n",
       "      (0): Tanh()\n",
       "      (1): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (agg_pred): AggPredictor(\n",
       "    (agg_lstm): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (agg_col_name_enc): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (agg_att): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (agg_out): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=768, out_features=6, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (agg_out_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (col_out_col): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (cond_pred): SQLNetCondPredictor(\n",
       "    (cond_num_lstm): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (cond_num_att): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (cond_num_out): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=768, out_features=5, bias=True)\n",
       "    )\n",
       "    (cond_num_name_enc): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (cond_num_col_att): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (cond_num_col2hid1): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (cond_num_col2hid2): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (cond_col_lstm): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (cond_col_att): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_col_name_enc): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (cond_col_out_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_col_out_col): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_col_out): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "    (cond_op_lstm): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (cond_op_att): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_op_out_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_op_name_enc): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (cond_op_out_col): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_op_out): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=768, out_features=4, bias=True)\n",
       "    )\n",
       "    (cond_str_lstm): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (cond_str_decoder): LSTM(200, 768, num_layers=2, batch_first=True, dropout=0.3)\n",
       "    (cond_str_name_enc): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (cond_str_out_g): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_str_out_h): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_str_out_col): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (cond_str_out): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (where_rela_pred): WhereRelationPredictor(\n",
       "    (where_rela_lstm): LSTM(768, 384, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    (where_rela_att): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (where_rela_col_att): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (where_rela_out): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=768, out_features=3, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (col2hid1): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (col2hid2): Linear(in_features=768, out_features=1536, bias=True)\n",
       "  )\n",
       "  (CE): CrossEntropyLoss()\n",
       "  (softmax): Softmax(dim=-1)\n",
       "  (log_softmax): LogSoftmax(dim=None)\n",
       "  (bce_logit): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert, tokenizer, bert_config = get_bert(bert_path)\n",
    "model = SQLNet(N_word=n_word, use_ca=True, gpu=True, trainable_emb=False)\n",
    "model_path = 'saved_model/best_model'\n",
    "print (\"Loading from %s\" % model_path)\n",
    "model.load_state_dict(torch.load(model_path,map_location='cpu'))\n",
    "print (\"Loaded model from %s\" % model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ad88d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sel': [1],\n",
       " 'agg': [0],\n",
       " 'cond_conn_op': 1,\n",
       " 'conds': [[0, 2, '长沙'], [3, 2, '3.17']]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = dev_sql[0]\n",
    "predict_input(model_bert, tokenizer, model, 1, sql, dev_table[sql['table_id']]['header'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
